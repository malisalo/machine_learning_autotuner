---
title: "Auto_HyperTuning"
output: html_document
date: "2024-07-17"
---

```{r}
library(caret)
library(missForest)
library(dplyr)
library(e1071)
library(randomForest)
library(gbm)
library(mice)
library(Hmisc)
library(missForest)
```

## Remove unused features
```{r}
df<- read.csv("all_years_leafs_final.csv")

remove_columns<- c("X",	"Season", "Plant_ID", "Genotype_ID_C", "Origin_Single",	"Origin_Grouped_by_Climate",	"Origin_Grouped_by_Region",	"Genetic_Origin")

df <- df[,-which(names(df) %in% remove_columns)]

write.csv(df, "/Users/malisalo/Documents/REEU2024/user_input_test.csv", row.names = FALSE)
```

## Data Imputations Methods
```{r}

perform_imputation<- function(technique, data) {
  func<- match.fun(technique)
  imputed_data <- func(data)
  return(imputed_data)
}
  # Perform MICE imputation
mice_impute<- function(data) {
  imputed_data <- mice(df, m = 5, maxit = 50, method = 'pmm', seed = 123)
  imputed_data <- complete(imputed_data)
  return(imputed_data)
}

missForest_impute<- function(data) {
  imputed_data <- missForest(data)
  data <- imputed_data$ximp
  return(data)
}

# Convert all character columns to factors
delete_na <- function(data) {
  data<- na.omit(data)
  return(data)
}
```

## Gradient Boosting
```{r}
create_gbm <- function(data, predicting_var, training_split) {
  # Split the data into training and test sets
  set.seed(123)
  trainIndex <- createDataPartition(data[[predicting_var]], p = training_split, list = FALSE, times = 1)
  train <- data[trainIndex, ]
  test <- data[-trainIndex, ]
  
  # Set up the tuning grid for hyperparameters
  tune_grid <- expand.grid(
    n.trees = c(50, 100, 150),
    interaction.depth = c(1, 3, 5),
    shrinkage = c(0.01, 0.1, 0.3),
    n.minobsinnode = 10
  )
  
  # Train control with cross-validation
  train_control <- trainControl(method = "cv", number = 5)
  
  # Train the Gradient Boosting model with hyperparameter tuning
  gbm_model <- train(as.formula(paste(predicting_var, "~ .")), 
                     data = train, 
                     method = "gbm",
                     metric = "Accuracy",
                     tuneGrid = tune_grid,
                     trControl = train_control,
                     verbose = FALSE)
  
  # Print the best parameters
  print(gbm_model$bestTune)
  
  # Use the best model to make predictions on the test set
  predictions_gbm <- predict(gbm_model, newdata = test)
  
  # Calculate confusion matrix
  cm_gbm <- confusionMatrix(predictions_gbm, test[[predicting_var]])
  
  # Print confusion matrix and overall accuracy
  print("Gradient Boosting")
  
  cat("Accuracy:", round(cm_gbm$overall['Accuracy'] * 100, 2), "%\n")
  print(cm_gbm)
  
  # Optionally return the tuned model and confusion matrix
  # return(list(model = gbm_model, confusion_matrix = cm_gbm))
}
```

## Random Forest
```{r}
create_rf<- function(data, predicting_var, training_split) {
  set.seed(123)
  train_index <- createDataPartition(data[[predicting_var]], 
                                     p = training_split, 
                                     list = FALSE, 
                                     times = 1)
  train <- data[train_index, ]
  test <- data[-train_index, ]

  # # Retrieve available core 
  # cl <- makeCluster(detectCores() - 1)
  # # Parallel Processing 
  # registerDoParallel(cl)

  # Train a Random Forest model with hyper parameter tuning
  tune_grid <- expand.grid(
    mtry = c(1:5),
    ntree = c(155, 255, 355, 555, 755, 1005), # Number of trees in the forest
    nodesize = c(1, 5, 10), # Minimum size of terminal nodes
    maxnodes = c(10, 20, 30) # Maximum number of terminal nodes
    )
  
  train_control <- trainControl(method = "cv", number = 5)

  model_rf <- train(as.formula(paste(predicting_var, "~ .")),
                    data = train, 
                    method = 'rf',
                    metric ="Accuracy",
                    tuneGrid = tune_grid, 
                    trControl = train_control,
                    importance = TRUE)

  # stopCluster(cl)

  predictions <- predict(model_rf, newdata= test)

  predictions <- factor(predictions, levels = levels(test$predicting_var))
  cm_rf <- confusionMatrix(predictions, test$predicting_var)
  
  # Print confusion matrix and overall accuracy
  print("Random Forest")
  cat("Accuracy:", round(cm_rf$overall['Accuracy'] * 100, 2), "%\n")

  # print(confusion_matrix)
  # print(model_rf)
}
```

## KNN
```{r}
create_knn <- function(data, predicting_var, training_split) {
  # Split the data into training and test sets
  set.seed(123)
  trainIndex <- createDataPartition(data[[predicting_var]], 
                                    p = training_split, 
                                    list = FALSE, 
                                    times = 1) 
  train <- data[trainIndex, ]
  test  <- data[-trainIndex, ]
  
  # Set up the tuning grid for k
  tune_grid <- expand.grid(
    k = c(1:20))  # Adjust the range as needed
  
  # Train control with cTreatross-validation
  train_control <- trainControl(method = "cv", number = 5, search = "grid")
  
  # Train the KNN model with hyperparameter tuning
  knn_tuned <- train(as.formula(paste(predicting_var, "~ .")), 
                     data = train, 
                     method = "knn",
                     metric = "Accuracy",
                     tuneGrid = tune_grid,
                     trControl = train_control)
  
  # Print the best parameters
  print(knn_tuned$bestTune)
  
  # Use the best model to make predictions on the test set
  predictions_knn <- predict(knn_tuned, newdata = test)
  
  # Calculate confusion matrix
  cm_knn <- confusionMatrix(predictions_knn, test[[predicting_var]])
  
  # Print confusion matrix and overall accuracy
  print("KNN")
  # print(cm_knn)
  cat("Accuracy:", round(cm_knn$overall['Accuracy'] * 100, 2), "%\n")
  
  # Optionally return the tuned model and confusion matrix
  # return(list(model = knn_tuned, confusion_matrix = cm_knn))
}

```

## SVM Classifier
```{r}
# Example function for SVM
create_svm <- function(data, predicting_var, training_split) {
  # Convert the target variable to a factor for classification
  data[[predicting_var]] <- as.factor(data[[predicting_var]])
  
  # Split the data into training and test sets
  set.seed(123)
  trainIndex <- createDataPartition(data[[predicting_var]], p = .8, list = FALSE, times = 1)
  train <- data[trainIndex, ]
  test <- data[-trainIndex, ]
  
  # Train control with cross-validation
  train_control <- trainControl(method = "cv", number = 5)
  
  # Train the SVM model
  svm_model <- train(
    as.formula(paste(predicting_var, "~ .")),
    data = train,
    method = "svmRadial",
    trControl = train_control)
  
  # Make predictions
  predictions <- predict(svm_model, newdata = test)
  
  # Calculate confusion matrix
  cm <- confusionMatrix(predictions, test[[predicting_var]])
  
  # Print confusion matrix and accuracy
  print("SVM")
  # print(cm)
  cat("Accuracy:", round(cm$overall['Accuracy'] * 100, 2), "%\n")
  
  # return(list(model = svm_model, confusion_matrix = cm))
}
```

## Test getting User's Input *** Connect to Front-End ***
```{r}
# Get user's input
# Prompt the user to select a file
selected_file <- file.choose()

# Check if a file was selected
if (!is.null(selected_file)) {
  # Read the CSV file into a dataframe
  user_data <- read.csv(selected_file)
  
  # Print the dataframe (optional)
  print(user_data)
} else {
  print("No file selected.")
}

user_data <- user_data %>%
    mutate_if(is.character, as.factor)

# str(user_data)

# Prompt the user for input
user_predicting <- readline(prompt = "What variable do you want to predict: ")

user_imputation<- readline(prompt = "Pick the missing data imputation Technique:")

user_split<- as.numeric(readline(prompt = "Pick split:"))

# Add more data inputs...

user_clean<- perform_imputation(user_imputation, user_data)

# create_rf(user_clean, user_predicting, user_split)
# create_knn(user_clean, user_predicting, user_split)
# create_svm(user_clean, user_predicting, user_split)
# create_gbm(user_clean, user_predicting, user_split)
create_rf(user_clean, user_predicting, user_split)
```






